# -*- coding: utf-8 -*-
"""MLR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YuWZbEfAlA2PhljpVXOjuVjm63ifI2pF

### 50_Startup Dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Data preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

#For modeling
from sklearn.linear_model import LinearRegression
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import mean_squared_error,r2_score
from sklearn import metrics

from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

df = pd.read_csv('/content/50_Startups.csv')
df.head()

df.shape

df.info()

df.describe()

df.isna().sum()

sum(df.duplicated())

"""We will plot between each of the attributes to if there is a correlation
*   Independent variables and dependent variables

*   Independent variables and other Independent variables
"""

sns.pairplot(df)

plt.figure(figsize=(10,8))
sns.set_context('paper',font_scale = 2)
corr_matrix=df.corr()
#annot will show the numbers inside each coloured box
sns.heatmap(corr_matrix,annot=True,cmap='Blues')

"""There is high correlation between(def.var and indep. var):

1. Profit and R&D spend
2. Profit and Marketing Spend

There is high correlation between(indep.var and indep.var):
1. Marketing spend and R&D spend

so, it's recommended to remove Administration column and either marketing spend or R&D otherwise it will cause multi
"""

corr_matrix

plt.figure(figsize=(10,4))
sns.distplot(df['Administration']);

plt.figure(figsize=(10,4))
sns.distplot(df['R&D Spend']);

plt.figure(figsize=(10,4))
sns.distplot(df['Marketing Spend']);

plt.figure(figsize=(10,4))
sns.distplot(df['Profit']);

#Since it normal distribution we do not need nay scaling

sns.countplot(x='State',data=df)

"""#**Variance Inflation Factor(VIF)

Vif test to check multicollinearity since we saw correlation between independet variables




"""

X=df[['R&D Spend','Administration','Marketing Spend']]
vif_data = pd.DataFrame()
vif_data["feature"] = X.columns
vif_data

vif_data["VIF"]= [variance_inflation_factor(X.values, i)
for i in range(len(X.columns))]
print(vif_data)

"""we can see R&D Spend and Marketing Spend have highest VIF values we can infer marketing Spend and R&D Spend

# Modeling
"""

def model_summary(x,y):
    xtr = sm.add_constant(np.array(df[x]))
    model = sm.OLS(np.array(df[y]), xtr).fit()
    print(model.summary())

"""here we create mini models for different combinations of dependent and independent variables using stats models api OLS function. We will use the rsquare and p value analysis for each mini model."""

model_summary('R&D Spend', 'Profit')

model_summary('Marketing Spend', 'Profit')

model_summary('Administration','Profit')

"""p value is large for Administration and Profit so we are adropping Adminitration"""

model_summary(['R&D Spend','Marketing Spend'],'Profit')

"""We will be dropping Marketing Spend because it has correlation with R&D Spend and it has low r^2 value and high p value"""

df.drop(columns=['Administration','Marketing Spend'],inplace = True)

X = df.iloc[:, :-1].values
y = df.iloc[:,-1].values

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')
X = np.array(ct.fit_transform(X))

"""Splitting the datatest into the training set and Test set"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)

"""Training the Multiple Linear Regression model on the training set"""

regressor = LinearRegression()
regressor.fit(X_train, y_train)

LinearRegression()

y_pred = regressor.predict(X_test)
np.set_printoptions(precision=2)
print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

print("MAE", metrics.mean_absolute_error(y_test, y_pred))
print("MSE", mean_squared_error(y_test, y_pred))
print("RMSE", np.sqrt(mean_squared_error(y_test, y_pred)))

r2_score(y_test,y_pred)

